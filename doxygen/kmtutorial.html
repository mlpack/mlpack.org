<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>mlpack: K-Means tutorial (kmeans)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.1 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="dirs.html"><span>Directories</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>K-Means tutorial (kmeans) </h1>  </div>
</div>
<div class="contents">
<h2><a class="anchor" id="intro_kmtut"></a>
Introduction</h2>
<p>The popular k-means algorithm for clustering has been around since the late 1950s, and the standard algorithm was proposed by Stuart Lloyd in 1957. Given a set of points <img class="formulaInl" alt="$ X $" src="form_58.png"/>, k-means clustering aims to partition each point <img class="formulaInl" alt="$ x_i $" src="form_97.png"/> into a cluster <img class="formulaInl" alt="$ c_j $" src="form_98.png"/> (where <img class="formulaInl" alt="$ j \le k $" src="form_99.png"/> and <img class="formulaInl" alt="$ k $" src="form_100.png"/>, the number of clusters, is a parameter). The partitioning is done to minimize the objective function</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \sum_{j = 1}^{k} \sum_{x_i \in c_j} \| x_i - \mu_j \|^2 \]" src="form_101.png"/>
</p>
<p>where <img class="formulaInl" alt="$\mu_j$" src="form_102.png"/> is the centroid of cluster <img class="formulaInl" alt="$c_j$" src="form_103.png"/>. The standard algorithm is a two-step algorithm:</p>
<ul>
<li><b>Assignment</b> <b>step</b>. Each point <img class="formulaInl" alt="$x_i$" src="form_104.png"/> in <img class="formulaInl" alt="$X$" src="form_105.png"/> is assigned to the cluster whose centroid it is closest to.</li>
</ul>
<ul>
<li><b>Update</b> <b>step</b>. Using the new cluster assignments, the centroids of each cluster are recalculated.</li>
</ul>
<p>The algorithm has converged when no more assignment changes are happening with each iteration. However, this algorithm can get stuck in local minima of the objective function and is particularly sensitive to the initial cluster assignments. Also, situations can arise where the algorithm will never converge but reaches steady state -- for instance, one point may be changing between two cluster assignments.</p>
<p>There is vast literature on the k-means algorithm and its uses, as well as strategies for choosing initial points effectively and keeping the algorithm from converging in local minima. <b>mlpack</b> does implement some of these, notably the Bradley-Fayyad algorithm (see the reference below) for choosing refined initial points. Importantly, the C++ <code>KMeans</code> class makes it very easy to improve the k-means algorithm in a modular way.</p>
<div class="fragment"><pre class="fragment">@inproceedings{bradley1998refining,
  title={Refining initial points <span class="keywordflow">for</span> k-means clustering},
  author={Bradley, Paul S. and Fayyad, Usama M.},
  booktitle={Proceedings of the Fifteenth International Conference on Machine
      Learning (ICML 1998)},
  volume={66},
  year={1998}
}
</pre></div><p><b>mlpack</b> provides:</p>
<ul>
<li>a <a class="el" href="kmtutorial.html#cli_kmtut">simple command-line executable</a> to run k-means</li>
<li>a <a class="el" href="kmtutorial.html#kmeans_kmtut">simple C++ interface</a> to run k-means</li>
<li>a <a class="el" href="kmtutorial.html#kmeans_template_kmtut">generic, extensible, and powerful C++ class</a> for complex usage</li>
</ul>
<h2><a class="anchor" id="toc_kmtut"></a>
Table of Contents</h2>
<p>A list of all the sections this tutorial contains.</p>
<ul>
<li><a class="el" href="kmtutorial.html#intro_kmtut">Introduction</a></li>
<li><a class="el" href="kmtutorial.html#toc_kmtut">Table of Contents</a></li>
<li><a class="el" href="kmtutorial.html#cli_kmtut">Command-Line 'kmeans'</a><ul>
<li><a class="el" href="kmtutorial.html#cli_ex1_kmtut">Simple k-means clustering</a></li>
<li><a class="el" href="kmtutorial.html#cli_ex2_kmtut">Saving the resulting centroids</a></li>
<li><a class="el" href="kmtutorial.html#cli_ex3_kmtut">Allowing empty clusters</a></li>
<li><a class="el" href="kmtutorial.html#cli_ex4_kmtut">Limiting the maximum number of iterations</a></li>
<li><a class="el" href="kmtutorial.html#cli_ex5_kmtut">Setting the overclustering factor</a></li>
<li><a class="el" href="kmtutorial.html#cli_ex6_kmtut">Using Bradley-Fayyad "refined start"</a></li>
</ul>
</li>
<li><a class="el" href="kmtutorial.html#kmeans_kmtut">The 'KMeans' class</a><ul>
<li><a class="el" href="kmtutorial.html#kmeans_ex1_kmtut">Running k-means and getting cluster assignments</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex2_kmtut">Running k-means and getting centroids of clusters</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex3_kmtut">Limiting the maximum number of iterations</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex4_kmtut">Setting the overclustering factor</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex5_kmtut">Setting initial cluster assignments</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex6_kmtut">Setting initial cluster centroids</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_ex7_kmtut">Running sparse k-means</a></li>
</ul>
</li>
<li><a class="el" href="kmtutorial.html#kmeans_template_kmtut">Template parameters for the 'KMeans' class</a><ul>
<li><a class="el" href="kmtutorial.html#kmeans_metric_kmtut">Changing the distance metric used for k-means</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_initial_partition_kmtut">Changing the initial partitioning strategy used for k-means</a></li>
<li><a class="el" href="kmtutorial.html#kmeans_empty_cluster_kmtut">Changing the action taken when an empty cluster is encountered</a></li>
</ul>
</li>
<li><a class="el" href="kmtutorial.html#further_doc_kmtut">Further documentation</a></li>
</ul>
<h2><a class="anchor" id="cli_kmtut"></a>
Command-Line 'kmeans'</h2>
<p><b>mlpack</b> provides a command-line executable, <code>kmeans</code>, to allow easy execution of the k-means algorithm on data. Complete documentation of the executable can be found by typing</p>
<div class="fragment"><pre class="fragment">$ kmeans --help
</pre></div><p>Below are several examples demonstrating simple use of the <code>kmeans</code> executable.</p>
<h3><a class="anchor" id="cli_ex1_kmtut"></a>
Simple k-means clustering</h3>
<p>We want to find 5 clusters using the points in the file dataset.csv. By default, if any of the clusters end up empty, that cluster will be reinitialized to contain the point furthest from the cluster with maximum variance. The cluster assignments of each point will be stored in assignments.csv. Each row in assignments.csv will correspond to the row in dataset.csv.</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -i dataset.csv -v -o assignments.csv
</pre></div><h3><a class="anchor" id="cli_ex2_kmtut"></a>
Saving the resulting centroids</h3>
<p>Sometimes it is useful to save the centroids of the clusters found by k-means; one example might be for plotting the points. The <code>-C</code> (<code>--centroid_file</code>) option allows specification of a file into which the centroids will be saved (one centroid per line, if it is a CSV or other text format).</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -i dataset.csv -v -o assignments.csv -C centroids.csv
</pre></div><h3><a class="anchor" id="cli_ex3_kmtut"></a>
Allowing empty clusters</h3>
<p>If you would like to allow empty clusters to exist, instead of reinitializing them, simply specify the <code>-e</code> (<code>--allow_empty_clusters</code>) option. Note that when you save your clusters, some of the clusters may be filled with NaNs. This is expected behavior -- if a cluster has no points, the concept of a centroid makes no sense.</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -i dataset.csv -v -o assignments.csv -C centroids.csv
</pre></div><h3><a class="anchor" id="cli_ex4_kmtut"></a>
Limiting the maximum number of iterations</h3>
<p>As mentioned earlier, the k-means algorithm can often fail to converge. In such a situation, it may be useful to stop the algorithm by way of limiting the maximum number of iterations. This can be done with the <code>-m</code> (<code>--max_iterations</code>) parameter, which is set to 1000 by default. If the maximum number of iterations is 0, the algorithm will run until convergence -- or potentially forever. The example below sets a maximum of 250 iterations.</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -i dataset.csv -v -o assignments.csv -m 250
</pre></div><h3><a class="anchor" id="cli_ex5_kmtut"></a>
Setting the overclustering factor</h3>
<p>The <b>mlpack</b> k-means implementation allows "overclustering", which is when the k-means algorithm is run with more than the requested number of clusters. Upon convergence, the clusters with the nearest centroids are merged until only the requested number of centroids remain. This can provide better clustering results. The overclustering factor, specified with <code>-O</code> or <code>--overclustering</code>, determines how many more clusters are found than were requested. For instance, with <code>k</code> set to 5 and an overclustering factor of 2, 10 clusters will be found. Note that the overclustering factor does not need to be an integer.</p>
<p>The following code snippet finds 5 clusters, but with an overclustering factor of 2.4 (so 12 clusters are found and then merged together to produce 5 final clusters).</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -O 2.4 -i dataset.csv -v -o assignments.csv
</pre></div><h3><a class="anchor" id="cli_ex6_kmtut"></a>
Using Bradley-Fayyad "refined start"</h3>
<p>The method proposed by Bradley and Fayyad in their paper "Refining initial
points for k-means clustering" is implemented in <b>mlpack</b>. This strategy samples points from the dataset and runs k-means clustering on those points multiple times, saving the resulting clusters. Then, k-means clustering is run on those clusters, yielding the original number of clusters. The centroids of those resulting clusters are used as initial centroids for k-means clustering on the entire dataset.</p>
<p>This technique generally gives better initial points than the default random partitioning, but depending on the parameters, it can take much longer. This initialization technique is enabled with the <code>-r</code> (<code>--refined_start</code>) option. The <code>-S</code> (<code>--samplings</code>) parameter controls how many samplings of the dataset are performed, and the <code>-p</code> (<code>--percentage</code>) parameter controls how much of the dataset is randomly sampled for each sampling (it must be between 0.0 and 1.0). For more information on the refined start technique, see the paper referenced in the introduction of this tutorial.</p>
<p>The example below performs k-means clustering, giving 5 clusters, using the refined start technique, sampling 10% of the dataset 25 times to produce the initial centroids.</p>
<div class="fragment"><pre class="fragment">$ kmeans -c 5 -i dataset.csv -v -o assignments.csv -r -S 25 -p 0.2
</pre></div><h2><a class="anchor" id="kmeans_kmtut"></a>
The 'KMeans' class</h2>
<p>The <code>KMeans&lt;&gt;</code> class (with default template parameters) provides a simple way to run k-means clustering using <b>mlpack</b> in C++. The default template parameters for <code>KMeans&lt;&gt;</code> will initialize cluster assignments randomly and disallow empty clusters. When an empty cluster is encountered, the point furthest from the cluster with maximum variance is set to the centroid of the empty cluster.</p>
<h3><a class="anchor" id="kmeans_ex1_kmtut"></a>
Running k-means and getting cluster assignments</h3>
<p>The simplest way to use the <code>KMeans&lt;&gt;</code> class is to pass in a dataset and a number of clusters, and receive the cluster assignments in return. Note that the dataset must be column-major -- that is, one column corresponds to one point. See <a class="el" href="matrices.html">the matrices guide</a> for more information.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;<a class="code" href="kmeans_8hpp.html">mlpack/methods/kmeans/kmeans.hpp</a>&gt;</span>

<span class="keyword">using namespace </span>mlpack::kmeans;

<span class="comment">// The dataset we are clustering.</span>
<span class="keyword">extern</span> arma::mat data;
<span class="comment">// The number of clusters we are getting.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// The assignments will be stored in this vector.</span>
arma::Col&lt;size_t&gt; assignments;

<span class="comment">// Initialize with the default arguments.</span>
KMeans&lt;&gt; k;
k.Cluster(data, clusters, assignments);
</pre></div><p>Now, the vector <code>assignments</code> holds the cluster assignments of each point in the dataset.</p>
<h3><a class="anchor" id="kmeans_ex2_kmtut"></a>
Running k-means and getting centroids of clusters</h3>
<p>Often it is useful to not only have the cluster assignments, but the centroids of each cluster. Another overload of <code>Cluster()</code> makes this easily possible:</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;<a class="code" href="kmeans_8hpp.html">mlpack/methods/kmeans/kmeans.hpp</a>&gt;</span>

<span class="keyword">using namespace </span>mlpack::kmeans;

<span class="comment">// The dataset we are clustering.</span>
<span class="keyword">extern</span> arma::mat data;
<span class="comment">// The number of clusters we are getting.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// The assignments will be stored in this vector.</span>
arma::Col&lt;size_t&gt; assignments;
<span class="comment">// The centroids will be stored in this matrix.</span>
arma::mat centroids;

<span class="comment">// Initialize with the default arguments.</span>
KMeans&lt;&gt; k;
k.Cluster(data, clusters, assignments, centroids);
</pre></div><p>Note that the centroids matrix has columns equal to the number of clusters and rows equal to the dimensionality of the dataset. Each column represents the centroid of the according cluster -- <code>centroids.col(0)</code> represents the centroid of the first cluster.</p>
<h3><a class="anchor" id="kmeans_ex3_kmtut"></a>
Limiting the maximum number of iterations</h3>
<p>The first argument to the constructor allows specification of the maximum number of iterations. This is useful because often, the k-means algorithm does not converge, and is terminated after a number of iterations. Setting this parameter to 0 indicates that the algorithm will run until convergence -- note that in some cases, convergence may never happen. The default maximum number of iterations is 1000.</p>
<div class="fragment"><pre class="fragment"><span class="comment">// The first argument is the maximum number of iterations.  Here we set it to</span>
<span class="comment">// 500 iterations.</span>
KMeans&lt;&gt; k(500);
</pre></div><p>Then you can run <code>Cluster()</code> as normal.</p>
<h3><a class="anchor" id="kmeans_ex4_kmtut"></a>
Setting the overclustering factor</h3>
<p>For a description of what overclustering is, see <a class="el" href="kmtutorial.html#cli_ex5_kmtut">the command-line interface tutorial about overclustering</a>.</p>
<p>The overclustering factor, which by default is 1.0 (this indicates that no overclustering is happening), is specified in the second argument to the constructor.</p>
<div class="fragment"><pre class="fragment"><span class="comment">// We will keep the default maximum iterations of 1000, but set the</span>
<span class="comment">// overclustering factor to 2.5.</span>
KMeans&lt;&gt; k(1000, 2.5);
</pre></div><p>Then you can run <code>Cluster()</code> as normal.</p>
<h3><a class="anchor" id="kmeans_ex5_kmtut"></a>
Setting initial cluster assignments</h3>
<p>If you have an initial guess for the cluster assignments for each point, you can fill the assignments vector with the guess and then pass an extra boolean (initialAssignmentGuess) as true to the <code>Cluster()</code> method. Below are examples for either overload of <code>Cluster()</code>.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;<a class="code" href="kmeans_8hpp.html">mlpack/methods/kmeans/kmeans.hpp</a>&gt;</span>

<span class="keyword">using namespace </span>mlpack::kmeans;

<span class="comment">// The dataset we are clustering on.</span>
<span class="keyword">extern</span> arma::mat dataset;
<span class="comment">// The number of clusters we are obtaining.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// A vector pre-filled with initial assignment guesses.</span>
<span class="keyword">extern</span> arma::Col&lt;size_t&gt; assignments;

KMeans&lt;&gt; k;

<span class="comment">// The boolean set to true indicates that our assignments vector is filled with</span>
<span class="comment">// initial guesses.</span>
k.Cluster(dataset, clusters, assignments, <span class="keyword">true</span>);
</pre></div><div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;<a class="code" href="kmeans_8hpp.html">mlpack/methods/kmeans/kmeans.hpp</a>&gt;</span>

<span class="keyword">using namespace </span>mlpack::kmeans;

<span class="comment">// The dataset we are clustering on.</span>
<span class="keyword">extern</span> arma::mat dataset;
<span class="comment">// The number of clusters we are obtaining.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// A vector pre-filled with initial assignment guesses.</span>
<span class="keyword">extern</span> arma::Col&lt;size_t&gt; assignments;

<span class="comment">// This will hold the centroids of the finished clusters.</span>
arma::mat centroids;

KMeans&lt;&gt; k;

<span class="comment">// The boolean set to true indicates that our assignments vector is filled with</span>
<span class="comment">// initial guesses.</span>
k.Cluster(dataset, clusters, assignments, centroids, <span class="keyword">true</span>);
</pre></div><dl class="note"><dt><b>Note:</b></dt><dd>If you have a heuristic or algorithm which makes initial guesses, a more elegant solution is to create a new class fulfilling the InitialPartitionPolicy template policy. See <a class="el" href="kmtutorial.html#kmeans_initial_partition_kmtut">the section about changing the initial partitioning strategy</a> for more details.</dd></dl>
<dl class="user"><dt><b></b></dt><dd></dd></dl>
<dl class="note"><dt><b>Note:</b></dt><dd>If you set the InitialPartitionPolicy parameter to something other than the default but give an initial cluster assignment guess, the InitialPartitionPolicy will not be used to initialize the algorithm. See <a class="el" href="kmtutorial.html#kmeans_initial_partition_kmtut">the section about changing the initial partitioning strategy</a> for more details.</dd></dl>
<h3><a class="anchor" id="kmeans_ex6_kmtut"></a>
Setting initial cluster centroids</h3>
<p>An equally important option to being able to make initial cluster assignment guesses is to make initial cluster centroid guesses without having to assign each point in the dataset to an initial cluster. This is similar to the previous section, but now you must pass two extra booleans -- the first (initialAssignmentGuess) as false, indicating that there are not initial cluster assignment guesses, and the second (initialCentroidGuess) as true, indicating that the centroids matrix is filled with initial centroid guesses.</p>
<p>This, of course, only works with the overload of <code>Cluster()</code> that takes a matrix to put the resulting centroids in. Below is an example.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;<a class="code" href="kmeans_8hpp.html">mlpack/methods/kmeans/kmeans.hpp</a>&gt;</span>

<span class="keyword">using namespace </span>mlpack::kmeans;

<span class="comment">// The dataset we are clustering on.</span>
<span class="keyword">extern</span> arma::mat dataset;
<span class="comment">// The number of clusters we are obtaining.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// A matrix pre-filled with guesses for the initial cluster centroids.</span>
<span class="keyword">extern</span> arma::mat centroids;

<span class="comment">// This will be filled with the final cluster assignments for each point.</span>
arma::Col&lt;size_t&gt; assignments;

KMeans&lt;&gt; k;

<span class="comment">// Remember, the first boolean indicates that we are not giving initial</span>
<span class="comment">// assignment guesses, and the second boolean indicates that we are giving</span>
<span class="comment">// initial centroid guesses.</span>
k.Cluster(dataset, clusters, assignments, centroids, <span class="keyword">false</span>, <span class="keyword">true</span>);
</pre></div><dl class="note"><dt><b>Note:</b></dt><dd>If you have a heuristic or algorithm which makes initial guesses, a more elegant solution is to create a new class fulfilling the InitialPartitionPolicy template policy. See <a class="el" href="kmtutorial.html#kmeans_initial_partition_kmtut">the section about changing the initial partitioning strategy</a> for more details.</dd></dl>
<dl class="user"><dt><b></b></dt><dd></dd></dl>
<dl class="note"><dt><b>Note:</b></dt><dd>If you set the InitialPartitionPolicy parameter to something other than the default but give an initial cluster centroid guess, the InitialPartitionPolicy will not be used to initialize the algorithm. See <a class="el" href="kmtutorial.html#kmeans_initial_partition_kmtut">the section about changing the initial partitioning strategy</a> for more details.</dd></dl>
<h3><a class="anchor" id="kmeans_ex7_kmtut"></a>
Running sparse k-means</h3>
<p>The <code>Cluster()</code> function can work on both sparse and dense matrices, so all of the above examples can be used with sparse matrices instead. Below is a simple example. Note that the centroids are returned as a sparse matrix also.</p>
<div class="fragment"><pre class="fragment"><span class="comment">// The sparse dataset.</span>
<span class="keyword">extern</span> arma::sp_mat sparseDataset;
<span class="comment">// The number of clusters.</span>
<span class="keyword">extern</span> <span class="keywordtype">size_t</span> clusters;

<span class="comment">// The assignments will be stored in this vector.</span>
arma::Col&lt;size_t&gt; assignments;
<span class="comment">// The centroids of each cluster will be stored in this sparse matrix.</span>
arma::sp_mat sparseCentroids;

<span class="comment">// No template parameter modification is necessary.</span>
KMeans&lt;&gt; k;
k.Cluster(sparseDataset, clusters, assignments, sparseCentroids);
</pre></div><h2><a class="anchor" id="kmeans_template_kmtut"></a>
Template parameters for the 'KMeans' class</h2>
<p>The <code>KMeans&lt;&gt;</code> class also takes three template parameters, which can be modified to change the behavior of the k-means algorithm. There are three template parameters:</p>
<ul>
<li><code>MetricType:</code> controls the distance metric used for clustering (by default, the squared Euclidean distance is used)</li>
<li><code>InitialPartitionPolicy:</code> the method by which initial clusters are set; by default, <a class="el" href="classmlpack_1_1kmeans_1_1RandomPartition.html">RandomPartition</a> is used</li>
<li><code>EmptyClusterPolicy:</code> the action taken when an empty cluster is encountered; by default, <a class="el" href="classmlpack_1_1kmeans_1_1MaxVarianceNewCluster.html">MaxVarianceNewCluster</a> is used</li>
</ul>
<p>The class is defined like below:</p>
<div class="fragment"><pre class="fragment"><span class="keyword">template</span>&lt;
  <span class="keyword">typename</span> DistanceMetric = <a class="code" href="classmlpack_1_1metric_1_1LMetric.html" title="The L_p metric for arbitrary integer p, with an option to take the root.">mlpack::metric::SquaredEuclideanDistance</a>,
  <span class="keyword">typename</span> InitialPartitionPolicy = RandomPartition,
  <span class="keyword">typename</span> EmptyClusterPolicy = MaxVarianceNewCluster
&gt;
<span class="keyword">class </span>KMeans;
</pre></div><p>In the following sections, each policy is described further, with examples of how to modify them.</p>
<h3><a class="anchor" id="kmeans_metric_kmtut"></a>
Changing the distance metric used for k-means</h3>
<p>Most machine learning algorithms in <b>mlpack</b> support modifying the distance metric, and <code>KMeans&lt;&gt;</code> is no exception. Similar to <a class="el" href="classmlpack_1_1neighbor_1_1NeighborSearch.html">NeighborSearch</a> (see <a class="el" href="nstutorial.html#metric_type_doc_nstut">the section in the NeighborSearch tutorial</a>), any class in <a class="el" href="namespacemlpack_1_1metric.html">mlpack::metric</a> can be given as an argument. The <a class="el" href="classmlpack_1_1metric_1_1LMetric.html" title="The L_p metric for arbitrary integer p, with an option to take the root.">mlpack::metric::LMetric</a> class is a good example implementation.</p>
<p>A class fulfilling the MetricType policy must provide the following two functions:</p>
<div class="fragment"><pre class="fragment"><span class="comment">// Empty constructor is required.</span>
MetricType();

<span class="comment">// Computer the distance between two points.</span>
<span class="keyword">template</span>&lt;<span class="keyword">typename</span> VecType&gt;
<span class="keywordtype">double</span> Evaluate(<span class="keyword">const</span> VecType&amp; a, <span class="keyword">const</span> VecType&amp; b);
</pre></div><p>Most of the standard metrics that could be used are stateless and therefore the <code>Evaluate()</code> method is implemented statically. However, there are metrics, such as the Mahalanobis distance (<a class="el" href="classmlpack_1_1metric_1_1MahalanobisDistance.html" title="The Mahalanobis distance, which is essentially a stretched Euclidean distance.">mlpack::metric::MahalanobisDistance</a>), that store state. To this end, an instantiated MetricType object is stored within the <code>KMeans</code> class. The example below shows how to pass an instantiated MahalanobisDistance in the constructor.</p>
<div class="fragment"><pre class="fragment"><span class="comment">// The initialized Mahalanobis distance.</span>
<span class="keyword">extern</span> <a class="code" href="classmlpack_1_1metric_1_1MahalanobisDistance.html" title="The Mahalanobis distance, which is essentially a stretched Euclidean distance.">mlpack::metric::MahalanobisDistance</a> distance;

<span class="comment">// We keep the default arguments for the maximum number of iterations and</span>
<span class="comment">// overclustering factor, but pass our instantiated metric.</span>
KMeans&lt;mlpack::metric::MahalanobisDistance&gt; k(1000, 1.0, distance);
</pre></div><dl class="note"><dt><b>Note:</b></dt><dd>While the MetricType policy only requires two methods, one of which is an empty constructor, more can always be added. <a class="el" href="classmlpack_1_1metric_1_1MahalanobisDistance.html" title="The Mahalanobis distance, which is essentially a stretched Euclidean distance.">mlpack::metric::MahalanobisDistance</a> also has constructors with parameters, because it is a stateful metric.</dd></dl>
<h3><a class="anchor" id="kmeans_initial_partition_kmtut"></a>
Changing the initial partitioning strategy used for k-means</h3>
<p>There have been many initial cluster strategies for k-means proposed in the literature. Fortunately, the <code>KMeans&lt;&gt;</code> class makes it very easy to implement one of these methods and plug it in without needing to modify the existing algorithm code at all.</p>
<p>By default, the <code>KMeans&lt;&gt;</code> class uses <a class="el" href="classmlpack_1_1kmeans_1_1RandomPartition.html" title="A very simple partitioner which partitions the data randomly into the number of desired clusters...">mlpack::kmeans::RandomPartition</a>, which randomly partitions points into clusters. However, writing a new policy is simple; it needs to only implement the following functions:</p>
<div class="fragment"><pre class="fragment"><span class="comment">// Empty constructor is required.</span>
InitialPartitionPolicy();

<span class="comment">// This function is called to initialize the clusters.</span>
<span class="keyword">template</span>&lt;<span class="keyword">typename</span> MatType&gt;
<span class="keywordtype">void</span> Cluster(MatType&amp; data,
             <span class="keyword">const</span> <span class="keywordtype">size_t</span> clusters,
             arma::Col&lt;size_t&gt; assignments);
</pre></div><p>The templatization of the <code>Cluster()</code> function allows both dense and sparse matrices to be passed in. If the desired policy does not work with sparse (or dense) matrices, then the method can be written specifically for one type of matrix -- however, be warned that if you try to use <code>KMeans</code> with that policy and the wrong type of matrix, you will get many ugly compilation errors!</p>
<div class="fragment"><pre class="fragment"><span class="comment">// The Cluster() function specialized for dense matrices.</span>
<span class="keywordtype">void</span> Cluster(arma::mat&amp; data,
             <span class="keyword">const</span> <span class="keywordtype">size_t</span> clusters,
             arma::Col&lt;size_t&gt; assignments);
</pre></div><p>One alternate to the default RandomPartition policy is the RefinedStart policy, which is an implementation of the Bradley and Fayyad approach for finding initial points detailed in "Refined initial points for k-means clustering" and other places in this document. Also see the documentation for <a class="el" href="classmlpack_1_1kmeans_1_1RefinedStart.html" title="A refined approach for choosing initial points for k-means clustering.">mlpack::kmeans::RefinedStart</a> for more information.</p>
<p>The <code>Cluster()</code> method must return valid initial assignments for every point in the dataset.</p>
<p>As with the MetricType template parameter, an initialized InitialPartitionPolicy can be passed to the constructor of <code>KMeans</code> as a fourth argument.</p>
<h3><a class="anchor" id="kmeans_empty_cluster_kmtut"></a>
Changing the action taken when an empty cluster is encountered</h3>
<p>Sometimes, during clustering, a situation will arise where a cluster has no points in it. The <code>KMeans</code> class allows easy customization of the action to be taken when this occurs. By default, the point furthest from the centroid of the cluster with maximum variance is taken as the centroid of the empty cluster; this is implemented in the <a class="el" href="classmlpack_1_1kmeans_1_1MaxVarianceNewCluster.html" title="When an empty cluster is detected, this class takes the point furthest from the centroid of the clust...">mlpack::kmeans::MaxVarianceNewCluster</a> class. Another alternate choice is the <a class="el" href="classmlpack_1_1kmeans_1_1AllowEmptyClusters.html" title="Policy which allows K-Means to create empty clusters without any error being reported.">mlpack::kmeans::AllowEmptyClusters</a> class, which simply allows empty clusters to persist.</p>
<p>A custom policy can be written and it must implement the following methods:</p>
<div class="fragment"><pre class="fragment"><span class="comment">// Empty constructor is required.</span>
EmptyClusterPolicy();

<span class="comment">// This function is called when an empty cluster is encountered.  emptyCluster</span>
<span class="comment">// indicates the cluster which is empty, and then the clusterCounts and</span>
<span class="comment">// assignments are meant to be modified by the function.  The function should</span>
<span class="comment">// return the number of modified points.</span>
<span class="keyword">template</span>&lt;<span class="keyword">typename</span> MatType&gt;
<span class="keywordtype">size_t</span> EmptyCluster(<span class="keyword">const</span> MatType&amp; data,
                    <span class="keyword">const</span> <span class="keywordtype">size_t</span> emptyCluster,
                    <span class="keyword">const</span> MatType&amp; centroids,
                    arma::Col&lt;size_t&gt;&amp; clusterCounts,
                    arma::Col&lt;size_t&gt;&amp; assignments);
</pre></div><p>The <code>EmptyCluster()</code> function is called for each cluster that is empty at each iteration of the algorithm. As with InitialPartitionPolicy, the <code>EmptyCluster()</code> function does not need to be generalized to support both dense and sparse matrices -- but usage with the wrong type of matrix will cause compilation errors.</p>
<p>Like the other template parameters to <code>KMeans</code>, EmptyClusterPolicy implementations that have state can be passed to the constructor of <code>KMeans</code> as a fifth argument. See the kmeans::KMeans documentation for further details.</p>
<h2><a class="anchor" id="further_doc_kmtut"></a>
Further documentation</h2>
<p>For further documentation on the KMeans class, consult the <a class="el" href="classmlpack_1_1kmeans_1_1KMeans.html">complete API documentation</a>. </p>
</div>
<hr class="footer"/><address class="footer"><small>Generated on Mon Apr 27 2015 16:48:27 for mlpack by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.1 </small></address>
</body>
</html>
